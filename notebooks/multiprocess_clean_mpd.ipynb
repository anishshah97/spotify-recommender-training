{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fb16e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import json\n",
    "from loguru import logger\n",
    "data_path = Path(Path(os.path.abspath(\"\")).parent, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed557609",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_mpd_dir = Path(data_path, \"01_raw\", \"spotify_mpd\")\n",
    "raw_mpd_slice_paths = {path.name.replace(\".json\", \"\"): path for path in raw_mpd_dir.glob(\"mpd.slice.*.json\")}\n",
    "cleaned_mpd_dir = Path(data_path, \"02_intermediate\", \"cleaned_spotify_mpd\")\n",
    "cleaned_mpd_slice_paths = {path.name.replace(\".parquet\", \"\").replace(\"_\", \".\"): path for path in cleaned_mpd_dir.glob(\"mpd_slice_*\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8384f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-21 03:00:27.602 | INFO     | __main__:<module>:2 - \n",
      "Number of files: 1000\n",
      "Number of files cleaned: 1000\n",
      "Number of files to clean: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "slices_to_clean = set(raw_mpd_slice_paths.keys())-set(cleaned_mpd_slice_paths.keys())\n",
    "logger.info(f\"\"\"\n",
    "Number of files: {len(raw_mpd_slice_paths)}\n",
    "Number of files cleaned: {len(cleaned_mpd_slice_paths)}\n",
    "Number of files to clean: {len(slices_to_clean)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d896031-2757-4fc1-a3f2-8c63ca771dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-21 02:36:27.806 | INFO     | __main__:<module>:2 - 1000\n"
     ]
    }
   ],
   "source": [
    "raw_slices_to_clean_paths = [(name,path) for name, path in raw_mpd_slice_paths.items() if name in slices_to_clean]\n",
    "logger.info(len(raw_slices_to_clean_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df58d71a-d572-46c6-a95f-2b0849e0f5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_slice_to_clean_path = raw_slices_to_clean_paths[0]\n",
    "base_path = cleaned_mpd_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38467b5c-db72-4215-9494-f6bc3a6fd6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_track_id_from_uri(uri):\n",
    "    return uri.split(\":\")[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ba14846-02c4-4f12-8bbc-c67e8f53e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "553db202-da0c-40f7-8781-08f466e72dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('mpd.slice.549000-549999',\n",
       " PosixPath('/Users/i854336/Documents/PERSONAL/Fourthbrain/Capstone/spotify-recommender-training/spotify-recommender-training/data/01_raw/spotify_mpd/mpd.slice.549000-549999.json'))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_slice_to_clean_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31bf7dda-ec63-42d7-aed6-a0e00c85101b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Match form of scraping for application and use this as these files to seed insert into a db\n",
    "#TODO: Read from DB and do operations like scrape songs whose features arent in the feature db\n",
    "def clean_mpd_slice(raw_slice_to_clean_path, base_path):\n",
    "    name = raw_slice_to_clean_path[0]\n",
    "    path = raw_slice_to_clean_path[1]\n",
    "    with open(path) as f:\n",
    "        play_lst = []\n",
    "        track_lst = []\n",
    "        seen_tracks = set()\n",
    "        data = json.load(f)\n",
    "        playlists = data[\"playlists\"]\n",
    "\n",
    "        # for each playlist\n",
    "        for playlist in playlists:\n",
    "            for track in playlist[\"tracks\"]:\n",
    "                if track[\"track_uri\"] not in seen_tracks:\n",
    "                    seen_tracks.add(track[\"track_uri\"])\n",
    "                    track_lst.append(track)\n",
    "            playlist[\"track_ids\"] = [parse_track_id_from_uri(x[\"track_uri\"]) for x in playlist[\"tracks\"]]\n",
    "            play_lst.append(playlist)\n",
    "\n",
    "        playlist_df = pd.DataFrame(play_lst)\n",
    "        playlist_table = pa.Table.from_pandas(playlist_df)\n",
    "\n",
    "        tracks_df = pd.DataFrame(track_lst)\n",
    "        tracks_df[\"track_id\"] = tracks_df.apply(lambda row: parse_track_id_from_uri(row[\"track_uri\"]), axis=1)\n",
    "        tracks_table = pa.Table.from_pandas(tracks_df)\n",
    "\n",
    "        cleaned_slice_dir = Path(base_path, name.replace(\".\", \"_\"))\n",
    "        cleaned_slice_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        pq.write_table(playlist_table, Path(cleaned_slice_dir, \"playlist.parquet\"), version=\"2.0\")\n",
    "        pq.write_table(tracks_table, Path(cleaned_slice_dir, \"tracks.parquet\"), version=\"2.0\")\n",
    "        \n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0406ec25-1736-40cf-9437-00043df20e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import repeat\n",
    "import concurrent.futures\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec98bd8a-fc13-432a-812a-f5d13e118a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [21:58,  1.32s/it]\n"
     ]
    }
   ],
   "source": [
    "MAX_THREADS = 30\n",
    "threads = min(MAX_THREADS, len(raw_slices_to_clean_paths))\n",
    "#BUG: ThreadPool or ProcessPool?\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=threads) as executor:\n",
    "    result = list(tqdm(executor.map(clean_mpd_slice, raw_slices_to_clean_paths, repeat(cleaned_mpd_dir))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf88bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SpotifyRecommendations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
